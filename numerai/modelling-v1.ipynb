{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a v1 numerai model\n",
    "\n",
    "## Goal\n",
    "Train a simple numerai model on subsampled data to dip our toes in the modelling. As\n",
    "an ancillary goal we will see how much does adding more data improves model performance.\n",
    "\n",
    "## Steps\n",
    "1. **[Subsample]** We will subsample the training and the validation data by sampling later eras more.\n",
    "   We ignore old training eras.\n",
    "2. **[Learning curve - num instances]** We will build a learning curve to see how much\n",
    "   increasing the amount of training eras and by extension number of training rows matters.\n",
    "3. **[Learning curve - num features]** We will do a similar analysis for different number of\n",
    "   features.\n",
    "4. **[XVal - Time split]** Finally we will test out the cross validation code shared by mdo.\n",
    "5. **[4th era sampling]** We will run the code once for a dataset where only every 4th era\n",
    "   is included. We will how much performance takes a hit this change accrues.\n",
    "\n",
    "For scoring we will use the simple pearson correlation and not the era based\n",
    "spearman score ie `numerai_score`.\n",
    "\n",
    "## Observations\n",
    "**[Learning curve - num instances]** Increasing the number of training samples does\n",
    " improve performance and we are very far from saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import metrics as nmr_metrics\n",
    "from tqdm.notebook import tqdm\n",
    "import shap\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.set_config_file(theme='pearl', sharing='public', offline=True)\n",
    "\n",
    "# Increase font size of matplotlib plots\n",
    "plt.rcParams['figure.figsize'] = 16, 8\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelling_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and save a smaller version for quicker startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_LOAD_SML_DATA = False\n",
    "ONLY_4TH_ERA = False\n",
    "MIN_TRAIN_ERA = 400\n",
    "\n",
    "TRAIN_DATA = \"../data/v4.1/train_int8.parquet\"\n",
    "VAL_DATA = \"../data/v4.1/validation_int8.parquet\"\n",
    "# Subsampled training and validation data for faster iteration\n",
    "SPLIT_DATA_4TH_ERA_FILE = \"../data/v4.1/split_dfs_sml.pkl\"\n",
    "SPLIT_DATA_ALL_RECENT_ERA_FILE = \"../data/v4.1/split_dfs_sml_4th_era.pkl\"\n",
    "SPLIT_DATA_FILE  = SPLIT_DATA_4TH_ERA_FILE if ONLY_4TH_ERA else SPLIT_DATA_ALL_RECENT_ERA_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TO_LOAD_SML_DATA:\n",
    "    split_dfs = mu.load_sampled_data(sampled_save_fl=SPLIT_DATA_FILE)\n",
    "else:\n",
    "    split_dfs = mu.sample_and_save_data(\n",
    "        train_path=TRAIN_DATA,\n",
    "        val_path=VAL_DATA,\n",
    "        train_min_erano=300,\n",
    "        sampled_save_fl=SPLIT_DATA_FILE,\n",
    "        only_4th_erano=ONLY_4TH_ERA,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = split_dfs[\"train\"], split_dfs[\"val\"]\n",
    "val_df = val_df[~val_df[\"target\"].isnull()]\n",
    "print(f\"{train_df.shape=}\")\n",
    "display(train_df.head(2))\n",
    "display(val_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of eras and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = mu.get_features(train_df)\n",
    "target = \"target\"\n",
    "eras = train_df.erano\n",
    "print(f\"{len(features)=}\\n\")\n",
    "print(eras.head())\n",
    "print()\n",
    "print(eras.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percent of different values in the target column of train_df.\n",
    "tgt_pct_df = (\n",
    "    np.round(train_df[target].value_counts(normalize=True)  * 100.).astype(int) # convert to pct\n",
    "    .reset_index()  # make series into df\n",
    "    .sort_values(by=target)  # is default sorted by proportions\n",
    ")\n",
    "# show a bar graph of the proportions in the pandas dataframe display.\n",
    "display(\n",
    "    tgt_pct_df\n",
    "    .style\n",
    "    .bar(subset=[\"proportion\"])\n",
    "    # show only 2 decimal places in target\n",
    "    .format({target: \"{:.2f}\"})\n",
    "    .set_caption(\"Percent of target values in train_df\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a learning curve\n",
    "\n",
    "Look at the model performance as we increase the number of eras in training. Let's ensure we always include the most recent eras and walk our way back to increasing more eras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = train_df.erano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of eras in the training data.\n",
    "eras.hist(bins=30);\n",
    "plt.title(f\"Distribution of eras in training\\nNumber of unique eras: {eras.nunique()}\");\n",
    "plt.xlabel(\"Era\");\n",
    "plt.ylabel(\"Count\");\n",
    "unique_eras = np.array(eras.unique())\n",
    "print(unique_eras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve data\n",
    "lc_data = []\n",
    "era_cnts = np.linspace(10, len(unique_eras), 4).astype(int)\n",
    "min_eras = [unique_eras[-era_cnt] for era_cnt in era_cnts]\n",
    "print(f\"{era_cnts=}\")\n",
    "print(f\"{min_eras=}\")\n",
    "X_val, y_val = val_df[features].astype(float), val_df[target].astype(float)\n",
    "\n",
    "for era_cnt, min_era in tqdm(\n",
    "    reversed(list(zip(era_cnts, min_eras))),\n",
    "    desc=\"Different number of eras in training data\",\n",
    "    total=len(era_cnts),\n",
    "):\n",
    "    print(f\"Training model with {era_cnt} eras and {min_era} min era...\")\n",
    "    model = lgb.LGBMRegressor(\n",
    "        colsample_bytree=0.006,\n",
    "        learning_rate=0.14,\n",
    "        max_depth=4,\n",
    "        n_estimators=2000,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    era_cnt_df = train_df[train_df.erano >= min_era]\n",
    "    print(\"Era limited training df shape:\", era_cnt_df.shape)\n",
    "    X_train, y_train = era_cnt_df[features].astype(float), era_cnt_df[target].astype(float)\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    lc_data.append(\n",
    "        {\n",
    "            \"min_era\": min_era,\n",
    "            \"num_eras\": era_cnt,\n",
    "            \"corr\": nmr_metrics.correlation_score(y_true=y_val, y_pred=model.predict(X_val)),\n",
    "            \"model\": model,\n",
    "        }\n",
    "    )\n",
    "    print(f\"Correlation score for {era_cnt=}: {lc_data[-1]['corr']}\\n\\n\")\n",
    "lc_df = pd.DataFrame(lc_data)\n",
    "display(lc_df.style.bar(subset=[\"corr\"]).format({\"corr\": \"{:.2f}\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lc_df[\"corr\"]);\n",
    "plt.title(\"Validation corr score vs. number of eras in training data\");\n",
    "plt.xlabel(\"Number of eras in training data\");\n",
    "plt.ylabel(\"Correlation score\");\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_data[0][\"model\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the models for the top 5 features.\n",
    "\n",
    "for i, lc_datum in enumerate(lc_data):\n",
    "    print(f\"Top 5 features for {era_cnts[i]} eras in training data\")\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": features,\n",
    "                \"importance\": lc_datum[\"model\"].feature_importances_,\n",
    "            }\n",
    "        )\n",
    "        .sort_values(by=\"importance\", ascending=False)\n",
    "        .head(5)\n",
    "        .style.bar(subset=[\"importance\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = []\n",
    "models = []\n",
    "settings = list(\n",
    "    it.product(\n",
    "        [0.006, 0.01],\n",
    "        [0.14],\n",
    "        [4],\n",
    "    ),\n",
    ")\n",
    "\n",
    "for lr, cs, md in settings:\n",
    "    models.append(\n",
    "        lgb.LGBMRegressor(\n",
    "            colsample_bytree=cs,\n",
    "            learning_rate=lr,\n",
    "            n_estimators=2000,\n",
    "            max_depth=md,\n",
    "            n_jobs=4,\n",
    "        )\n",
    "    )\n",
    "for model in tqdm(models):\n",
    "    score = np.mean(\n",
    "        model_selection.cross_val_score(\n",
    "            model,\n",
    "            train_df[features].astype(np.float16),\n",
    "            train_df[target],\n",
    "            cv=nmr_metrics.TimeSeriesSplitGroups(5),\n",
    "            n_jobs=1,\n",
    "            groups=eras,\n",
    "            scoring=metrics.make_scorer(nmr_metrics.correlation_score, greater_is_better=True),\n",
    "            error_score=\"raise\",\n",
    "        )\n",
    "    )\n",
    "    cv_score.append(score)\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(len(cv_score)), np.array(cv_score))\n",
    "plt.xticks(range(len(cv_score)), settings)\n",
    "plt.xlabel(\"Setting\");\n",
    "plt.ylabel(\"CV score\");\n",
    "plt.title(\"CV score for different settings\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model on the full training data\n",
    "chosen_model = models[cv_score.index(max(cv_score))]\n",
    "chosen_model.fit(train_df[features].astype(np.float16), train_df[target])\n",
    "display(chosen_model)\n",
    "\n",
    "# Compute the numerai_score on the validation data\n",
    "val_preds = chosen_model.predict(val_df[features].astype(np.float16))\n",
    "numerai_score = nmr_metrics.numerai_score(\n",
    "    y_pred=val_preds, y_true=val_df[target], eras=val_df.erano,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(models[0])\n",
    "shap_values = explainer(train_df[features].astype(np.float16))\n",
    "shap.summary_plot(shap_values, train_df[features].astype(np.float16), plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
